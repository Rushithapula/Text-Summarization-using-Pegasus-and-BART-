The project's contributions and significance lie in implementing and evaluating the performance
of Pegasus and BART models for abstractive text summarization. These models have been
shown to achieve state-of-the-art results in various NLP tasks, and their application to abstractive
text summarization can have practical implications in various domains, such as news
summarization, content generation, and information retrieval. The project's findings can help
improve the efficiency of summarization tasks, providing users with relevant and concise
summaries of lengthy texts, saving time and effort in information retrieval by making analysis
between the models and predict the accurate model for abstractive text summarization.
